{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf3fbb2b04f4bb4bdda41df845cda5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/csgrad/sunilruf/'\n",
    "path = \"/home/csgrad/sunilruf/emotion_chatbot/master/sunils_code/mistra/rank_64/rank_64_2/checkpoint-50\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForCausalLM.from_pretrained(path, load_in_4bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = '../../../ExTES.json'  # Change 'output.json' to your desired file name\n",
    "\n",
    "# Write the list to the JSON file\n",
    "with open(json_file_path, 'rb') as json_file:\n",
    "    extes_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"thu-coai/esconv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experience_type': 'Current Experience',\n",
       " 'emotion_type': 'depression',\n",
       " 'problem_type': 'ongoing depression',\n",
       " 'situation': 'I am always depressed and the upcoming holidays are making it a lot worse.',\n",
       " 'survey_score': {'seeker': {'initial_emotion_intensity': '4',\n",
       "   'empathy': '5',\n",
       "   'relevance': '5',\n",
       "   'final_emotion_intensity': '3'},\n",
       "  'supporter': {'relevance': '5'}},\n",
       " 'dialog': [{'text': 'Hello. How are you today?',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Others'},\n",
       "  {'text': 'hi i am okay, a little bit sad though', 'speaker': 'usr'},\n",
       "  {'text': 'Okay. I am very sorry to hear that! Do you want to tell me more about that?',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Question'},\n",
       "  {'text': 'Well with the holidays coming up i have been very stressed and nervous about what i am going to do',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'I really feel you there. Holidays are so hard.. especially with the way this year has been. Anything specific?',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Affirmation and Reassurance'},\n",
       "  {'text': \"Yes. I am a college student and I live on campus. The day before I moved in my dad said some unforgivable things to me and we haven't spoke since\",\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'I have no choice but to go live at home over the break but I am very scared about it',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': \"Do you feel scared for your own self? Or of the situation in general? I'm sorry to hear that. Relationships with parents can be very difficult sometimes.\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Question'},\n",
       "  {'text': \"I'm around college age as well and also live at home. So I can understand your struggle.\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Self-disclosure'},\n",
       "  {'text': 'more for the situation in general. i know we will not speak but we will constantly be running into each other, my house is not big.',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'and i have no car to escape it', 'speaker': 'usr'},\n",
       "  {'text': \"It's like we live the same life. I also have no car to escape! It seems so small, but it's such a huge stressor when you feel trapped in an environment you're not positive in. I feel your pain and I empathize with you completely.\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Self-disclosure'},\n",
       "  {'text': \"It'll be hard but I hope you can make it through it throughout the holidays and enjoy yourself some. Are there any pros to going back home? Any pets?\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Affirmation and Reassurance'},\n",
       "  {'text': 'Thank you I appreciate that. I will be fine making it over the thanksgiving break but I am more nervous about covid-19 sending us home for good.',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'Not many to be honest. I have a hamster but he is at school with me so nothing at home to go back to',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': \"It sounds like Covid- 19 is going to be a personal stressor for you. It's such a strange thing to have to live with already, the pandemic, and i'm sorry that it might end up pushing you where you don't want to be.\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Restatement or Paraphrasing'},\n",
       "  {'text': 'Could you bring your hamster home with you? Even the smallest things could help a place feel more loving',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Providing Suggestions'},\n",
       "  {'text': \"Yes it is very strange and I know that it is a big stressor on all of us, i don't want to sound selfish.\",\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'Yes i am bringing him home with me so that is my little piece of joy that is coming along',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': \"I don't think you're selfish at all. You have feelings you are entitled to have and are expressing them which is healthy and I encourage that behavior!\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Affirmation and Reassurance'},\n",
       "  {'text': 'Good! I know how hard this situation can be. Very nerve wracking. The smallest things, even a hamster, can be so beneficial.',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Providing Suggestions'},\n",
       "  {'text': 'Well thank you that does help me to feel better. Yes I am happy to bring him home with me and hoping I can have my niece over to intro duce her to him',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'You sound like a very determined person in making this trip as stress free as possible. I commend you for that! Maybe you could have your niece over often to play with your hamster just to soften the stress of being there',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Reflection of feelings'},\n",
       "  {'text': 'It is surely my goal! I appreciate your kind words. I would love that if I had a car I could do that but I am not sure how much she will be able to come to my house. I am going to try though!',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': \"Is Uber an option for you? I know there's a lot of rideshare services but they're not always financially reasonable. But that could be a way to get away if you ever need too!\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Providing Suggestions'},\n",
       "  {'text': \"that is very true i didn't even think of that to be honest! I may use that along the way, thank you for the reminder!\",\n",
       "   'speaker': 'usr'},\n",
       "  {'text': \"Sometimes I forget little things like that to help myself whenever I get too involved in the emotional aspect of things. I'm glad I could suggest it to you!\",\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Self-disclosure'},\n",
       "  {'text': 'Thank you! Well i appreciate your help a lot and hope you have a great day!',\n",
       "   'speaker': 'usr'},\n",
       "  {'text': 'Of course! I hope you do as well and happy holidays!',\n",
       "   'speaker': 'sys',\n",
       "   'strategy': 'Others'}],\n",
       " 'seeker_question1': 'They did good and helped me a lot',\n",
       " 'seeker_question2': 'Nope it was all good',\n",
       " 'supporter_question1': 'Good task !',\n",
       " 'supporter_question2': 'Nope!'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(dataset['test'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/csgrad/sunilruf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def generate_content(tokenizer, messages):\n",
    "    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=128,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.95\n",
    "        )\n",
    "        \n",
    "        val = (tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].split(\"[/INST]\")[-1])\n",
    "    \n",
    "    return val, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User': 'Hey there', 'AI Strategy': '', 'AI': 'Hi, how are you doing today?'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! How can I help you today?\n",
      " Hello there! How can I help you today?\n",
      "torch.Size([1, 10, 32000])\n",
      "torch.Size([1, 9, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.5263, device='cuda:0')\n",
      "tensor(29.3700, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User': \"I have tried talking to them, but it feels like we just can't seem to understand each other anymore. Every conversation turns into an argument, and it's really frustrating. I miss the way things used to be between us.\", 'AI Strategy': 'Empathetic Statements', 'AI': \"It sounds like you're yearning for the connection you once had with your friend. It can be difficult when communication becomes strained, especially with someone you're close to. It's completely understandable that you miss the way things used to be.\"}\n",
      " I understand how difficult it can be when communication breaks down and it feels like there's a disconnect between you. It's completely normal to miss the way things used to be and feel frustrated when arguments occur.\n",
      "I can understand how frustrating it must be when conversations turn into arguments, especially when it feels like you're not being heard. It's tough when you miss the way things used to be between you and your loved one.\n",
      "torch.Size([1, 76, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51, 32000])\n",
      "tensor(9.7453, device='cuda:0')\n",
      "tensor(53.9628, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User': \"I'll definitely give that a try. It's important to approach the conversation with a level head and really listen to what they have to say. I hope it helps us to reconnect and find a way forward. Thanks for the suggestion!\", 'AI Strategy': 'Affirmation', 'AI': \"You're welcome! Taking a calm and open-minded approach can certainly create a space for healthier communication. Just remember that rebuilding a relationship takes time and effort from both sides. I'm here for you if you need any further support or guidance. Wishing you the best of luck!\"}\n",
      " You're absolutely right. Approaching the conversation with empathy and a willingness to listen can go a long way in improving communication. I hope you find some progress and are able to reconnect with your loved one. You're doing great!\n",
      "you're taking proactive steps, which is great. remember, communication takes effort from both sides. hope reconnecting brings positive change. best of luck!\n",
      "torch.Size([1, 178, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 109, 32000])\n",
      "tensor(6.6948, device='cuda:0')\n",
      "tensor(64.3374, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_length = 1024\n",
    "stride = 128\n",
    "\n",
    "#encodings = tokenizer.encode_plus(data['dialog'][1]['text'], return_tensors=\"pt\").to('cuda')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "seq_len = 1024\n",
    "\n",
    "nlls = []\n",
    "nlls_boh = []\n",
    "prev_end_loc = 0\n",
    "messages = []\n",
    "i = 1\n",
    "perplexity = []\n",
    "for j in range(1):\n",
    "    num = random.choice(range(3000, len(extes_data)))\n",
    "    #num = 10000\n",
    "    data = extes_data[num]['content']\n",
    "    \n",
    "    #data = data\n",
    "    messages = []\n",
    "    messages_boh = []\n",
    "    for i in range(0, len(data), 2):\n",
    "        for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "            print(data[i])\n",
    "            messages.append({\"role\": \"user\", \"content\":  data[i]['User']})\n",
    "            messages_boh.append({\"role\": \"user\", \"content\":  remove_stopwords(data[i]['User'])})\n",
    "            i+=2\n",
    "            end_loc = min(begin_loc + max_length, seq_len)\n",
    "            trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "            #input_ids = encodings.input_ids[:, begin_loc:end_loc].to('cuda')\n",
    "            input_ids = tokenizer.apply_chat_template(messages, tokenize=True, truncation=False, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "            input_ids_boh = tokenizer.apply_chat_template(messages_boh, tokenize=True, truncation=False, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids_boh = input_ids_boh.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "            target_ids_boh[:, :-trg_len] = -100\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                \n",
    "                val, _ = generate_content(tokenizer, messages)\n",
    "                val_boh, _ = generate_content(tokenizer, messages_boh)\n",
    "                outputs = model(input_ids, labels=target_ids)\n",
    "                print(val)\n",
    "                print(val_boh)\n",
    "                messages.append({\"role\": \"assistant\", \"content\": val})\n",
    "                print(outputs.logits.shape)\n",
    "                outputs_boh = model(input_ids_boh, labels=target_ids_boh)\n",
    "                print(outputs_boh.logits.shape)\n",
    "                messages_boh.append({\"role\": \"assistant\", \"content\": remove_stopwords(val_boh)})\n",
    "                    \n",
    "                \n",
    "                neg_log_likelihood = outputs.loss\n",
    "                neg_log_likelihood_boh = outputs_boh.loss\n",
    "                #print(neg_log_likelihood.shape)\n",
    "\n",
    "            nlls.append(neg_log_likelihood)\n",
    "            nlls_boh.append(neg_log_likelihood_boh)\n",
    "            #print(len(nlls))\n",
    "            prev_end_loc = end_loc\n",
    "            if end_loc == seq_len:\n",
    "                break\n",
    "\n",
    "        ppl = torch.exp(torch.stack(nlls).mean())\n",
    "        ppl_boh = torch.exp(torch.stack(nlls_boh).mean())\n",
    "        print(ppl)\n",
    "        print(ppl_boh)\n",
    "        perplexity.append(ppl)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dialog'][i]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd love to chat with you! What's been on your mind?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I can understand how that must be challenging for you. It sounds like you're really juggling a lot of responsibilities right now.\n",
      " Hello! Mind refers to the mental processes, consciousness, thoughts, and perceptions that we have as human beings. It's the complex system of cognitive abilities that enable us to learn, remember, think, problem-solve, and communicate. Is there a specific aspect of the mind you'd like to discuss?\n",
      "torch.Size([1, 25, 32000])\n",
      "torch.Size([1, 20, 32000])\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3466, device='cuda:0')\n",
      "tensor(72.4942, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm having problems with friends - or more precisely the lack of them. I don't have any.\n",
      " I'm really sorry to hear that. It's tough when you're feeling lonely and disconnected from others. Can you tell me more about what you're experiencing?\n",
      "I understand. It can be really challenging to navigate friendships without feeling supported or understood. Is there any specific reason why you feel alone in your friendships?\n",
      "torch.Size([1, 84, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 81, 32000])\n",
      "2\n",
      "tensor(7.8755, device='cuda:0')\n",
      "tensor(71.3503, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well it's more that I think I've never had friends. Not anyone I can confide in or laugh with\n",
      " That sounds incredibly difficult. It can be very isolating and disheartening when you're longing for companionship but haven't found it yet. Have you considered joining any social groups or clubs that align with your interests?\n",
      "hearing that. feeling excluded from close relationships can be incredibly isolating. it's important to remember that you deserve genuine connections and companionship.\n",
      "torch.Size([1, 154, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 121, 32000])\n",
      "3\n",
      "tensor(6.8837, device='cuda:0')\n",
      "tensor(69.4126, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't think I'd want to let them know how unhappy I am to be honest\n",
      " I understand why you might feel hesitant about sharing your emotions with others. It takes courage to open up and reveal your vulnerabilities. However, if you're open to it, maybe there's someone you trust or can confide in, such as a therapist or a trusted friend.\n",
      "absolutely. being authentic, expressing vulnerability, can create deeper, more authentic friendships. it might be uncomfortable initially, but over time, it can strengthen bonds.\n",
      "torch.Size([1, 229, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 158, 32000])\n",
      "4\n",
      "tensor(6.1702, device='cuda:0')\n",
      "tensor(66.8474, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've never heard of friendship apps to be honest\n",
      " Friendship apps can be a viable option for meeting new people and expanding your social circle. They provide a platform for individuals to connect based on common interests and goals. Have you considered exploring this avenue?\n",
      "you're not alone. many people hesitant use apps create meaningful connections. remember, these tools designed help people connect, build friendships. even if not perfect, they can provide opportunities meet potential friends.\n",
      "torch.Size([1, 308, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 200, 32000])\n",
      "5\n",
      "tensor(5.6328, device='cuda:0')\n",
      "tensor(63.6757, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But it sounds to me that you are pretty overall sad right now. You don't want family to know about how sad you are. Do you think it's more than just feeling like you don't have any friends?\n",
      " It's true that I've been feeling quite sad lately, but it's not only about the lack of friends. I've been struggling with feelings of loneliness and worthlessness, which has been impacting my overall wellbeing. It's been a challenging journey for me.\n",
      "I understand. feeling sad and yearning for meaningful friendships can be overwhelming. it's okay to share your emotions with family. they care about you and want to support.\n",
      "torch.Size([1, 404, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 260, 32000])\n",
      "6\n",
      "tensor(5.3530, device='cuda:0')\n",
      "tensor(60.8117, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On most of the apps, it connects you with people in your town!\n",
      " Yes, you're right. Friendship apps are designed to help people connect with others in their local area. It's a great way to meet new people and potentially form meaningful connections. Have you given it a try?\n",
      "yes, absolutely! apps like Meetup, Tinder Social, Bumble BFF can connect you with people in your local area. Give it a try!\n",
      "torch.Size([1, 489, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 296, 32000])\n",
      "7\n",
      "tensor(5.1262, device='cuda:0')\n",
      "tensor(58.2880, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know if it's more than that. What do you mean?\n",
      " I mean, it could be possible that your feelings of sadness and loneliness go beyond the lack of friends. It's important to explore the underlying causes of your emotions and seek support accordingly. Have you considered reaching out to a mental health professional or a trusted friend for guidance?\n",
      "I meant, using apps to connect with like-minded individuals in your town could be a great way to expand your social circle.\n",
      "torch.Size([1, 561, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 334, 32000])\n",
      "8\n",
      "tensor(4.9178, device='cuda:0')\n",
      "tensor(55.5654, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well personally, I have struggled with putting myself down a lot and blaming myself for things that I shouldn't blame myself for. You shouldn't blame yourself for not having the courage to go meet people, or blame yourself for not having any friends! And if that is what you are struggling with, then I think the apps would be a really good first step for you! You can create those bonds and connections with people close by to you on there first, and then when you feel comfortable enough with them you can meet up\n",
      " Thank you for your kind words and support. You're right, I often put myself down and blame myself, but it's important to remember that everyone deserves to have companionship and friends. Starting with the apps can be a great way to build confidence and connect with others in a safe and comfortable environment. I'll give it a try!\n",
      "I understand. It's normal to have self-doubt and blame ourselves for not being able to connect with others. Using apps as a first step can be a great way to build confidence and create meaningful connections. Remember, it's okay to take things at your own pace.\n",
      "torch.Size([1, 734, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 404, 32000])\n",
      "9\n",
      "tensor(4.8219, device='cuda:0')\n",
      "tensor(53.9259, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh you mean chat online first, before actually meeting in person?\n",
      " Yes, exactly! It can be a good way to get to know someone and build a connection before taking the next step of meeting in person. It can also help reduce anxiety or uncertainty that might come with meeting someone new.\n",
      "yes, exactly! Chat online first, get to know someone, then decide if you want to meet in person. This way, you have opportunity build rapport before making any plans.\n",
      "torch.Size([1, 826, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 454, 32000])\n",
      "10\n",
      "tensor(4.7291, device='cuda:0')\n",
      "tensor(52.3691, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's so cool. Thanks for your help\n",
      " You're welcome! I'm glad I could provide some guidance and support. Remember, you deserve to have meaningful relationships and connections in your life. Don't give up on yourself or your happiness. Good luck with the apps!\n",
      "you're welcome! Remember, you're not alone in this. Take small steps, be open, and I'm here for you.\n",
      "torch.Size([1, 889, 32000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 494, 32000])\n",
      "11\n",
      "tensor(4.6386, device='cuda:0')\n",
      "tensor(50.7945, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m29\u001b[39m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m begin_loc \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, seq_len, stride)):\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdialog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m         messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:  data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialog\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[1;32m     20\u001b[0m         messages_boh\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:  remove_stopwords(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialog\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])})\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_length = 1024\n",
    "stride = 128\n",
    "\n",
    "#encodings = tokenizer.encode_plus(data['dialog'][1]['text'], return_tensors=\"pt\").to('cuda')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "seq_len = 1024\n",
    "data = json.loads(dataset['test'][2]['text'])\n",
    "nlls = []\n",
    "prev_end_loc = 0\n",
    "messages = []\n",
    "messages_boh = []\n",
    "i = 1\n",
    "while i<29:\n",
    "    for begin_loc in (range(0, seq_len, stride)):\n",
    "        #print(data['dialog'][i]['text'])\n",
    "        messages.append({\"role\": \"user\", \"content\":  data['dialog'][i]['text']})\n",
    "        messages_boh.append({\"role\": \"user\", \"content\":  remove_stopwords(data['dialog'][i]['text'])})\n",
    "        i+=2\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        #input_ids = encodings.input_ids[:, begin_loc:end_loc].to('cuda')\n",
    "        input_ids = tokenizer.apply_chat_template(messages, tokenize=True, truncation=False, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "        input_ids_boh = tokenizer.apply_chat_template(messages_boh, tokenize=True, truncation=False, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids_boh = input_ids_boh.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "        target_ids_boh[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            val, _ = generate_content(tokenizer, messages)\n",
    "            val_boh, _ = generate_content(tokenizer, messages_boh)\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            print(val)\n",
    "            print(val_boh)\n",
    "            messages.append({\"role\": \"assistant\", \"content\": val})\n",
    "            print(outputs.logits.shape)\n",
    "            outputs_boh = model(input_ids_boh, labels=target_ids_boh)\n",
    "            print(outputs_boh.logits.shape)\n",
    "            messages_boh.append({\"role\": \"assistant\", \"content\": remove_stopwords(val_boh)})\n",
    "                \n",
    "            \n",
    "            neg_log_likelihood = outputs.loss\n",
    "            neg_log_likelihood_boh = outputs_boh.loss\n",
    "            #print(neg_log_likelihood.shape)\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "        nlls_boh.append(neg_log_likelihood_boh)\n",
    "            \n",
    "        print(len(nlls))\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "    #print(ppl)\n",
    "    ppl_boh = torch.exp(torch.stack(nlls_boh).mean())\n",
    "    print(ppl)\n",
    "    print(ppl_boh)\n",
    "    perplexity.append(ppl)\n",
    "    #messages.append({\"role\": \"assistant\", \"content\": val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
