{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/csgrad/sunilruf/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "import evaluate\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "from tqdm import tqdm\n",
    "smoothie = SmoothingFunction().method4\n",
    "rouge = evaluate.load('rouge')\n",
    "messages_final = json.load(open('data/messages_final.json'))\n",
    "messages_boh_original_final = json.load(open('data/messages_boh_original_final.json'))\n",
    "messages_no_sw_original_final = json.load(open('data/messages_no_sw_original_final.json'))\n",
    "test_data = json.load(open('data/test_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/csgrad/sunilruf/'\n",
    "path = \"/home/csgrad/sunilruf/emotion_chatbot/master/sunils_code/mistra/rank_64/rank_16_2/checkpoint-50/\"\n",
    "torch.cuda.empty_cache()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"thu-coai/esconv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:31<25:53, 31.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22\n",
      "1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:39<26:13, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:26<29:16, 38.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 36\n",
      "4 0\n",
      "5 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [03:32<20:24, 28.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [04:19<22:46, 32.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [05:12<25:37, 37.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 42\n",
      "9 0\n",
      "10 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [05:45<15:15, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [06:13<15:17, 24.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [07:01<17:55, 29.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 39\n",
      "14 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [07:35<14:07, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 26\n",
      "16 0\n",
      "17 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [08:22<10:43, 20.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [08:57<11:38, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 27\n",
      "20 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [09:46<11:00, 23.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 36\n",
      "22 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [10:21<09:24, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [11:05<10:43, 25.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [11:34<10:37, 26.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24\n",
      "26 0\n",
      "27 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [12:05<06:34, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 23\n",
      "29 0\n",
      "30 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [12:32<04:28, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [13:00<04:49, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 21\n",
      "33 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [13:34<04:13, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 27\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [14:03<00:46,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 24\n",
      "44 0\n",
      "45 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [15:23<00:00, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 65\n",
      "47 0\n",
      "48 0\n",
      "49 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bleu_2_final, bleu_2_boh_original_final, bleu_2_no_sw_original_final = [], [], []\n",
    "bleu_4_final, bleu_4_boh_original_final, bleu_4_no_sw_original_final = [], [], []\n",
    "bert_score_final, bert_score_boh_original_final, bert_score_no_sw_original_final = [], [], []\n",
    "rouge_final, rouge_boh_original_final, rouge_no_sw_original_final = [], [], []\n",
    "meteor_final, meteor_boh_original_final, meteor_no_sw_original_final = [], [], []\n",
    "\n",
    "for j in tqdm(range(3, 53)):\n",
    "    data = json.loads(dataset['test'][j]['text'])\n",
    "    data = data['dialog']\n",
    "    j = j-3\n",
    "    try:\n",
    "        for i in range(0, len(data),1):\n",
    "            #print(i)\n",
    "            if data[i+1]['speaker'] == \"sys\":\n",
    "                reference = data[i+1]['text']\n",
    "            elif data[i+2]['speaker'] == \"sys\":\n",
    "                reference = data[i+1]['text']\n",
    "            elif data[i+3]['speaker'] == \"sys\":\n",
    "                reference = data[i+1]['text']\n",
    "            #print(messages_final[j][i]['content'])\n",
    "            \n",
    "            bleu_2_final.append(sentence_bleu(messages_final[j][i]['content'], reference, weights=(0.5,0.5), smoothing_function=smoothie))\n",
    "            bleu_2_boh_original_final.append(sentence_bleu(messages_boh_original_final[j][i]['content'], reference, weights=(0.5,0.5), smoothing_function=smoothie))\n",
    "            bleu_2_no_sw_original_final.append(sentence_bleu(messages_no_sw_original_final[j][i]['content'], reference, weights=(0.5,0.5), smoothing_function=smoothie))\n",
    "            bleu_4_final.append(sentence_bleu(messages_final[j][i]['content'], reference, weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothie))\n",
    "            bleu_4_boh_original_final.append(sentence_bleu(messages_boh_original_final[j][i]['content'], reference, weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothie))\n",
    "            bleu_4_no_sw_original_final.append(sentence_bleu(messages_no_sw_original_final[j][i]['content'], reference, weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothie))\n",
    "            bert_score_final.append(score([messages_final[j][i]['content']], [reference], lang='en', model_type='bert-base-uncased'))\n",
    "            bert_score_boh_original_final.append(score([messages_boh_original_final[j][i]['content']], [reference], lang='en', model_type='bert-base-uncased'))\n",
    "            bert_score_no_sw_original_final.append(score([messages_no_sw_original_final[j][i]['content']], [reference], lang='en', model_type='bert-base-uncased'))\n",
    "            rouge_final.append(rouge.compute(predictions=[messages_final[j][i]['content']], references=[reference]))\n",
    "            rouge_boh_original_final.append(rouge.compute(predictions=[messages_boh_original_final[j][i]['content']], references=[reference]))\n",
    "            rouge_no_sw_original_final.append(rouge.compute(predictions=[messages_no_sw_original_final[j][i]['content']], references=[reference]))\n",
    "            meteor_final.append((nltk.translate.meteor_score.meteor_score([word_tokenize(messages_final[j][i]['content'])], word_tokenize(reference))))\n",
    "            meteor_boh_original_final.append((nltk.translate.meteor_score.meteor_score([word_tokenize(messages_boh_original_final[j][i]['content'])], word_tokenize(reference))))\n",
    "            meteor_no_sw_original_final.append((nltk.translate.meteor_score.meteor_score([word_tokenize(messages_no_sw_original_final[j][i]['content'])], word_tokenize(reference))))\n",
    "            \n",
    "    except:\n",
    "        print(j,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rougel_final = [i['rougeL'] for i in rouge_final]\n",
    "rougel_boh_original_final = [i['rougeL'] for i in rouge_boh_original_final]\n",
    "rougel_no_sw_original_final = [i['rougeL'] for i in rouge_no_sw_original_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_p_boh = [i[0].item() for i in bert_score_boh_original_final]\n",
    "bert_r_boh = [i[1].item() for i in bert_score_boh_original_final]\n",
    "bert_f1_boh = [i[2].item() for i in bert_score_boh_original_final]\n",
    "\n",
    "bert_p_no_sw = [i[0].item() for i in bert_score_no_sw_original_final]\n",
    "bert_r_no_sw = [i[1].item() for i in bert_score_no_sw_original_final]\n",
    "bert_f1_no_sw = [i[2].item() for i in bert_score_no_sw_original_final]\n",
    "\n",
    "bert_p = [i[0].item() for i in bert_score_final]\n",
    "bert_r = [i[1].item() for i in bert_score_final]\n",
    "bert_f1 = [i[2].item() for i in bert_score_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu 2 Final:  0.04957757090498865\n",
      "Bleu 2 Boh Original Final:  0.04903233914141645\n",
      "Bleu 2 No Sw Original Final:  0.04857005628140412\n",
      "Bleu 4 Final:  0.012798795480772743\n",
      "Bleu 4 Boh Original Final:  0.012722933710740895\n",
      "Bleu 4 No Sw Original Final:  0.012669187262289678\n",
      "Rouge L Final:  0.12630593607153845\n",
      "Rouge L Boh Original Final:  0.1282707451016453\n",
      "Rouge L No Sw Original Final:  0.11609526455569318\n",
      "Bert Precision Final:  0.40962716490872164\n",
      "Bert Recall Final:  0.4401547888998931\n",
      "Bert F1 Final:  0.42005367690728884\n",
      "Bert Precision Boh Original Final:  0.40952830477538754\n",
      "Bert Recall Boh Original Final:  0.42478142840798294\n",
      "Bert F1 Boh Original Final:  0.4134836722438955\n",
      "Bert Precision No Sw Original Final:  0.41169440706318383\n",
      "Bert Recall No Sw Original Final:  0.41719828202983755\n",
      "Bert F1 No Sw Original Final:  0.4108598335819729\n",
      "Meteor Final:  0.1214522739356365\n",
      "Meteor Boh Original Final:  0.12303861719762525\n",
      "Meteor No Sw Original Final:  0.12241994402193376\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print(\"Bleu 2 Final: \", statistics.mean(bleu_2_final))\n",
    "print(\"Bleu 2 Boh Original Final: \", statistics.mean(bleu_2_boh_original_final))\n",
    "print(\"Bleu 2 No Sw Original Final: \", statistics.mean(bleu_2_no_sw_original_final))\n",
    "print(\"Bleu 4 Final: \", statistics.mean(bleu_4_final))\n",
    "print(\"Bleu 4 Boh Original Final: \", statistics.mean(bleu_4_boh_original_final))\n",
    "print(\"Bleu 4 No Sw Original Final: \", statistics.mean(bleu_4_no_sw_original_final))\n",
    "print(\"Rouge L Final: \", statistics.mean(rougel_final))\n",
    "print(\"Rouge L Boh Original Final: \", statistics.mean(rougel_boh_original_final))\n",
    "print(\"Rouge L No Sw Original Final: \", statistics.mean(rougel_no_sw_original_final))\n",
    "print(\"Bert Precision Final: \", statistics.mean(bert_p))\n",
    "print(\"Bert Recall Final: \", statistics.mean(bert_r))\n",
    "print(\"Bert F1 Final: \", statistics.mean(bert_f1))\n",
    "print(\"Bert Precision Boh Original Final: \", statistics.mean(bert_p_boh))\n",
    "print(\"Bert Recall Boh Original Final: \", statistics.mean(bert_r_boh))\n",
    "print(\"Bert F1 Boh Original Final: \", statistics.mean(bert_f1_boh))\n",
    "print(\"Bert Precision No Sw Original Final: \", statistics.mean(bert_p_no_sw))\n",
    "print(\"Bert Recall No Sw Original Final: \", statistics.mean(bert_r_no_sw))\n",
    "print(\"Bert F1 No Sw Original Final: \", statistics.mean(bert_f1_no_sw))\n",
    "print(\"Meteor Final: \", statistics.mean(meteor_final))\n",
    "print(\"Meteor Boh Original Final: \", statistics.mean(meteor_boh_original_final))\n",
    "print(\"Meteor No Sw Original Final: \", statistics.mean(meteor_no_sw_original_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "perplexity_final = torch.load('data/perplexity_final.pt')\n",
    "perplexity_boh = torch.load('data/perplexity_boh_final.pt')\n",
    "perplexity_sw = torch.load('data/perplexity_no_sw_final.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Final:  tensor(8.9637)\n",
      "Perplexity Boh Original Final:  tensor(57.2150)\n",
      "Perplexity No Sw Original Final:  tensor(55.1800)\n"
     ]
    }
   ],
   "source": [
    "perplexity_final1 = []\n",
    "perplexity_final1.extend(per for sublist in perplexity_final for per in sublist )\n",
    "perplexity_boh1 = []\n",
    "perplexity_boh1.extend(per for sublist in perplexity_boh for per in sublist )\n",
    "perplexity_sw1 = []\n",
    "perplexity_sw1.extend(per for sublist in perplexity_sw for per in sublist )\n",
    "\n",
    "print(\"Perplexity Final: \", torch.mean(torch.tensor(perplexity_final1)))\n",
    "print(\"Perplexity Boh Original Final: \", torch.mean(torch.tensor(perplexity_boh1)))\n",
    "print(\"Perplexity No Sw Original Final: \", torch.mean(torch.tensor(perplexity_sw1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "messages_boh = json.load(open('data/messages_boh_final.json'))\n",
    "messages_sw = json.load(open('data/messages_no_sw_final.json'))\n",
    "messages_final = json.load(open('data/messages_final.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'My friends trying shame me'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I here listen It really when friends try shame you Remember you deserve respect kindness from those around you It stand up for yourself communicate your feelings If you need help figuring out how handle situation I here support you'},\n",
       " {'role': 'user', 'content': 'How'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'First acknowledge their behavior express your feelings about it For example you say I feel hurt disrespected when you shame me like that Then set boundaries communicate your expectations For instance you say I appreciate spoken to in manner I appreciate if you show me respect Finally offer solution behavior that more For example you suggest Instead of shaming me we discuss our concerns work together find solution'},\n",
       " {'role': 'user',\n",
       "  'content': 'It Christmas my friends say that I donate to charity'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It sounds like your friends questioning your decision donate to charity during Christmas It remember that everyone has right make their choices especially when it comes to giving If you feel you explain to them why giving back to you how it aligns with your values Additionally you consider sharing some of impact your donations made in past Hopefully through communication your friends come appreciate support your giving'},\n",
       " {'role': 'user',\n",
       "  'content': 'They putting me on guilt trip My one friend President of profit'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand your friend putting you on guilt trip especially when they president of company It constantly feel like you doing enough Remember that everyone has circumstances situations It prioritize your well being compare yourself to others You gently communicate your concerns feelings to your friend expressing how their pressure affecting you You also consider setting boundaries focusing on your goals aspirations instead of constantly comparing yourself to their success'},\n",
       " {'role': 'user', 'content': 'I making income with COVID-19 either'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand how it during COVID-19 downturn make income It stay keep exploring options Even if income limited right now there are still ways generate revenue find sources of income It also connect with organizations networks that provide resources for entrepreneurs self employed individuals in your area'},\n",
       " {'role': 'user', 'content': 'Two so called friends of mine need get life'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It sounds like you have two friends who struggling with their lives you feeling about it Remember that everyone goes through times needs support It there for them while also setting boundaries for your well You try encouraging them seek help simply listening ear when they need someone talk to'},\n",
       " {'role': 'user',\n",
       "  'content': 'people know that just because my two friends go Way back mean they hurt me emotionally'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand your perspective about hurt in friendships Just because people known for time mean they right hurt you emotionally It communicate your feelings set boundaries that protect your well being'},\n",
       " {'role': 'user', 'content': 'What I do about two so called friends'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'First take care of yourself prioritize your well boundaries communicate your feelings to your friends If they respect your boundaries consider distancing yourself from them Remember that your happiness'},\n",
       " {'role': 'user', 'content': 'they know that I in trouble myself'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It acknowledge that they also struggling themselves It challenging for them understand your perspective as well You try having conversation with them about how their actions affecting you express your need for support without towards their struggles'},\n",
       " {'role': 'user', 'content': 'COVID-19 wrecked my income levels'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand how challenging it when income levels affected by circumstances like COVID-19 It take time adjust find ways generate income I encourage you stay be to exploring opportunities as freelance work starting your business'},\n",
       " {'role': 'user', 'content': 'Things time year'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It sounds like you going through time It completely feel Remember you in this I here listen support you'},\n",
       " {'role': 'user', 'content': 'I do that'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'you taking steps support yourself there anything else you like talk about share'},\n",
       " {'role': 'user', 'content': 'I used donate LOT in year past'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It that you used donate lot in past It give back to others Remember that taking care of yourself also If you ever need someone talk to I here'},\n",
       " {'role': 'user', 'content': 'point'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand you feeling with amount of donations you made in past It prioritize your needs wellbeing hesitate reach out if you need someone talk to if you have concerns'},\n",
       " {'role': 'user',\n",
       "  'content': 'My friends like know that I trading time instead of donating money'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It understand your friends perception about your trading time instead of donating money It communicate your reasoning behind your decision to them They fully understand your situation so explaining how it aligns with your values help clarify'},\n",
       " {'role': 'user', 'content': 'you make point'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I appreciate you understanding my perspective It always have communication with friends about their concerns your needs'},\n",
       " {'role': 'user',\n",
       "  'content': 'that people just want shame people without knowing their plight'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I agree that it for people shame others without understanding their plight It approach situations with empathy understanding'},\n",
       " {'role': 'user',\n",
       "  'content': 'I need think of others ways contribute that have my friends hating on me'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It understand your desire contribute in ways that your friends approve It brainstorming ways that align with your values interests while still of others'},\n",
       " {'role': 'user', 'content': 'I have pride too'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I completely understand your pride desire stand up for yourself It find balance between your needs expectations of others'},\n",
       " {'role': 'user', 'content': ''},\n",
       " {'role': 'assistant',\n",
       "  'content': \"You in this I here listen support you through your struggles Remember it prioritize yourself your wellbeing Let 's explore ways you find happiness fulfillment in your life What things that you enjoy doing what your passions\"},\n",
       " {'role': 'user',\n",
       "  'content': 'problem that I it my friends going believe me I well individual'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand how challenging it when your friends believe you It isolating It remember that you individual with your thoughts feelings It communicate your perspective clearly to your friends provide evidence support your position Additionally it finding support system outside of your friend group'},\n",
       " {'role': 'user', 'content': 'We only hope for 2021'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I share your hope for 2021 It year filled with opportunities for growth change I encourage you set goals for yourself reflect on your strengths Let 's work together make of 2021\"},\n",
       " {'role': 'user', 'content': 'how quickly markets rebound'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'It depends on factors as policies government response It challenging predict exactly how quickly markets rebound approach staying informed about market trends preparing for changes'},\n",
       " {'role': 'user',\n",
       "  'content': 'I usually go to their get togethers Both of my friends well do'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I understand that you usually attend your friends gatherings Both of them enjoy your presence It find ways connect with them virtually while staying during time You suggest video calls planning activities that allow distancing'},\n",
       " {'role': 'user', 'content': 'you'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'You I here support you Remember take care of yourself hesitate reach out if you need someone talk to You doing'},\n",
       " {'role': 'user', 'content': 'Thank you'},\n",
       " {'role': 'assistant', 'content': 'You'},\n",
       " {'role': 'user', 'content': 'Happy Holidays'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Holidays to you Remember take care of yourself enjoy holidays If you need anything I here for you'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_boh[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:00<00:00, 362.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual length  56.229268292682924\n",
      "boh length  23.507317073170732\n",
      "sw length  18.390243902439025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "boh_length, sw_length, final_length = [], [], []\n",
    "for j in tqdm(range(0,47)):\n",
    "    for i in range(1,len(messages_final[j]),2):\n",
    "        final_length.append(len(tokenizer.tokenize(messages_final[j][i]['content'])))\n",
    "        sw_length.append(len(tokenizer.tokenize(messages_sw[j][i]['content'])))\n",
    "        boh_length.append(len(tokenizer.tokenize(messages_boh[j][i]['content'])))\n",
    "        \n",
    "print(\"actual length \", statistics.mean(final_length))\n",
    "print(\"boh length \", statistics.mean(boh_length))\n",
    "print(\"sw length \", statistics.mean(sw_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
