{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/csgrad/sunilruf/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from bert_score import score\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "import evaluate\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "from tqdm import tqdm\n",
    "smoothie = SmoothingFunction().method4\n",
    "rouge = evaluate.load('rouge')\n",
    "messages_final = json.load(open('messages_final.json'))\n",
    "messages_boh_original_final = json.load(open('messages_boh_original_final.json'))\n",
    "messages_no_sw_original_final = json.load(open('messages_no_sw_original_final.json'))\n",
    "test_data = json.load(open('test_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/csgrad/sunilruf/'\n",
    "path = \"/home/csgrad/sunilruf/emotion_chatbot/master/sunils_code/mistra/rank_64/rank_16_2/checkpoint-50/\"\n",
    "torch.cuda.empty_cache()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\"Hello, how are you today?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages_final), len(messages_boh_original_final), len(messages_no_sw_original_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages_final[0]), len(messages_boh_original_final[0]), len(messages_no_sw_original_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [21:25<00:00, 12.85s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "bleu_2_final, bleu_2_boh_original_final, bleu_2_no_sw_original_final = [], [], []\n",
    "bleu_4_final, bleu_4_boh_original_final, bleu_4_no_sw_original_final = [], [], []\n",
    "bert_score_final, bert_score_boh_original_final, bert_score_no_sw_original_final = [], [], []\n",
    "rouge_final, rouge_boh_original_final, rouge_no_sw_original_final = [], [], []\n",
    "meteor_final, meteor_boh_original_final, meteor_no_sw_original_final = [], [], []\n",
    "\n",
    "for j in tqdm(range(100)):\n",
    "    \n",
    "    for i in range(1, len(test_data[j]),2):\n",
    "        #print(i)\n",
    "        if messages_final[j][i]['content'] == '' or test_data[j][i]['content'] == '' or messages_boh_original_final[j][i]['content'] == '' or messages_no_sw_original_final[j][i]['content'] == '':\n",
    "            continue\n",
    "        #print(messages_final[j][i]['content'])\n",
    "        \n",
    "        bleu_2_final.append(sentence_bleu(messages_final[j][i]['content'], test_data[j][i]['content'], weights=(0.5,0.5), smoothing_function=smoothie))\n",
    "        bleu_2_boh_original_final.append(sentence_bleu(messages_boh_original_final[j][i]['content'], test_data[j][i]['content'], weights=(0.5,0.5), smoothing_function=smoothie))\n",
    "        bleu_2_no_sw_original_final.append(sentence_bleu(messages_no_sw_original_final[j][i]['content'], test_data[j][i]['content'], weights=(0.5,0.5), smoothing_function=smoothie))\n",
    "        bleu_4_final.append(sentence_bleu(messages_final[j][i]['content'], test_data[j][i]['content'], weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothie))\n",
    "        bleu_4_boh_original_final.append(sentence_bleu(messages_boh_original_final[j][i]['content'], test_data[j][i]['content'], weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothie))\n",
    "        bleu_4_no_sw_original_final.append(sentence_bleu(messages_no_sw_original_final[j][i]['content'], test_data[j][i]['content'], weights=(0.25,0.25,0.25,0.25), smoothing_function=smoothie))\n",
    "        bert_score_final.append(score([messages_final[j][i]['content']], [test_data[j][i]['content']], lang='en', model_type='bert-base-uncased'))\n",
    "        bert_score_boh_original_final.append(score([messages_boh_original_final[j][i]['content']], [test_data[j][i]['content']], lang='en', model_type='bert-base-uncased'))\n",
    "        bert_score_no_sw_original_final.append(score([messages_no_sw_original_final[j][i]['content']], [test_data[j][i]['content']], lang='en', model_type='bert-base-uncased'))\n",
    "        rouge_final.append(rouge.compute(predictions=[messages_final[j][i]['content']], references=[test_data[j][i]['content']]))\n",
    "        rouge_boh_original_final.append(rouge.compute(predictions=[messages_boh_original_final[j][i]['content']], references=[test_data[j][i]['content']]))\n",
    "        rouge_no_sw_original_final.append(rouge.compute(predictions=[messages_no_sw_original_final[j][i]['content']], references=[test_data[j][i]['content']]))\n",
    "        meteor_final.append((nltk.translate.meteor_score.meteor_score([word_tokenize(messages_final[j][i]['content'])], word_tokenize(test_data[j][i]['content']))))\n",
    "        meteor_boh_original_final.append((nltk.translate.meteor_score.meteor_score([word_tokenize(messages_boh_original_final[j][i]['content'])], word_tokenize(test_data[j][i]['content']))))\n",
    "        meteor_no_sw_original_final.append((nltk.translate.meteor_score.meteor_score([word_tokenize(messages_no_sw_original_final[j][i]['content'])], word_tokenize(test_data[j][i]['content']))))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rougel_final = [i['rougeL'] for i in rouge_final]\n",
    "rougel_boh_original_final = [i['rougeL'] for i in rouge_boh_original_final]\n",
    "rougel_no_sw_original_final = [i['rougeL'] for i in rouge_no_sw_original_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_p_boh = [i[0].item() for i in bert_score_boh_original_final]\n",
    "bert_r_boh = [i[1].item() for i in bert_score_boh_original_final]\n",
    "bert_f1_boh = [i[2].item() for i in bert_score_boh_original_final]\n",
    "\n",
    "bert_p_no_sw = [i[0].item() for i in bert_score_no_sw_original_final]\n",
    "bert_r_no_sw = [i[1].item() for i in bert_score_no_sw_original_final]\n",
    "bert_f1_no_sw = [i[2].item() for i in bert_score_no_sw_original_final]\n",
    "\n",
    "bert_p = [i[0].item() for i in bert_score_final]\n",
    "bert_r = [i[1].item() for i in bert_score_final]\n",
    "bert_f1 = [i[2].item() for i in bert_score_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu 2 Final:  0.023692008143055214\n",
      "Bleu 2 Boh Original Final:  0.022857128164688597\n",
      "Bleu 2 No Sw Original Final:  0.022651871236492992\n",
      "Bleu 4 Final:  0.005390839336131438\n",
      "Bleu 4 Boh Original Final:  0.005293997520894258\n",
      "Bleu 4 No Sw Original Final:  0.005270120133785091\n",
      "Rouge L Final:  0.29875519616293467\n",
      "Rouge L Boh Original Final:  0.23433511035044557\n",
      "Rouge L No Sw Original Final:  0.23055794902071927\n",
      "Bert Precision Final:  0.6236151706279637\n",
      "Bert Recall Final:  0.6341298861585\n",
      "Bert F1 Final:  0.626973126296955\n",
      "Bert Precision Boh Original Final:  0.563170210429619\n",
      "Bert Recall Boh Original Final:  0.5434744501494626\n",
      "Bert F1 Boh Original Final:  0.5501792549036673\n",
      "Bert Precision No Sw Original Final:  0.600833372299104\n",
      "Bert Recall No Sw Original Final:  0.5502295829519827\n",
      "Bert F1 No Sw Original Final:  0.5712984863028653\n",
      "Meteor Final:  0.34693737737028274\n",
      "Meteor Boh Original Final:  0.2812788387187525\n",
      "Meteor No Sw Original Final:  0.32224831258546205\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print(\"Bleu 2 Final: \", statistics.mean(bleu_2_final))\n",
    "print(\"Bleu 2 Boh Original Final: \", statistics.mean(bleu_2_boh_original_final))\n",
    "print(\"Bleu 2 No Sw Original Final: \", statistics.mean(bleu_2_no_sw_original_final))\n",
    "print(\"Bleu 4 Final: \", statistics.mean(bleu_4_final))\n",
    "print(\"Bleu 4 Boh Original Final: \", statistics.mean(bleu_4_boh_original_final))\n",
    "print(\"Bleu 4 No Sw Original Final: \", statistics.mean(bleu_4_no_sw_original_final))\n",
    "print(\"Rouge L Final: \", statistics.mean(rougel_final))\n",
    "print(\"Rouge L Boh Original Final: \", statistics.mean(rougel_boh_original_final))\n",
    "print(\"Rouge L No Sw Original Final: \", statistics.mean(rougel_no_sw_original_final))\n",
    "print(\"Bert Precision Final: \", statistics.mean(bert_p))\n",
    "print(\"Bert Recall Final: \", statistics.mean(bert_r))\n",
    "print(\"Bert F1 Final: \", statistics.mean(bert_f1))\n",
    "print(\"Bert Precision Boh Original Final: \", statistics.mean(bert_p_boh))\n",
    "print(\"Bert Recall Boh Original Final: \", statistics.mean(bert_r_boh))\n",
    "print(\"Bert F1 Boh Original Final: \", statistics.mean(bert_f1_boh))\n",
    "print(\"Bert Precision No Sw Original Final: \", statistics.mean(bert_p_no_sw))\n",
    "print(\"Bert Recall No Sw Original Final: \", statistics.mean(bert_r_no_sw))\n",
    "print(\"Bert F1 No Sw Original Final: \", statistics.mean(bert_f1_no_sw))\n",
    "print(\"Meteor Final: \", statistics.mean(meteor_final))\n",
    "print(\"Meteor Boh Original Final: \", statistics.mean(meteor_boh_original_final))\n",
    "print(\"Meteor No Sw Original Final: \", statistics.mean(meteor_no_sw_original_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "messages_boh = json.load(open('messages_boh_final.json'))\n",
    "messages_sw = json.load(open('messages_no_sw_final.json'))\n",
    "messages_final = json.load(open('messages_final.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 519.08it/s]\n"
     ]
    }
   ],
   "source": [
    "boh_length, sw_length, final_length = [], [], []\n",
    "for j in tqdm(range(100)):\n",
    "    for i in range(1,len(messages_final[j]),2):\n",
    "        final_length.append(len(tokenizer.tokenize(messages_final[j][i]['content'])))\n",
    "        sw_length.append(len(tokenizer.tokenize(messages_sw[j][i]['content'])))\n",
    "        boh_length.append(len(tokenizer.tokenize(messages_boh[j][i]['content'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual length  50.67349137931034\n",
      "boh length  23.955818965517242\n",
      "sw length  19.72521551724138\n"
     ]
    }
   ],
   "source": [
    "print(\"actual length \", statistics.mean(final_length))\n",
    "print(\"boh length \", statistics.mean(boh_length))\n",
    "print(\"sw length \", statistics.mean(sw_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "perplexity_final = torch.load('perplexity_final.pt')\n",
    "perplexity_boh = torch.load('perplexity_boh_final.pt')\n",
    "perplexity_sw = torch.load('perplexity_no_sw_final.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_final1 = []\n",
    "perplexity_final1.extend(per for sublist in perplexity_final for per in sublist )\n",
    "perplexity_boh1 = []\n",
    "perplexity_boh1.extend(per for sublist in perplexity_boh for per in sublist )\n",
    "perplexity_sw1 = []\n",
    "perplexity_sw1.extend(per for sublist in perplexity_sw for per in sublist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Final:  tensor(5.4749)\n",
      "Perplexity Boh Original Final:  tensor(60.8528)\n",
      "Perplexity No Sw Original Final:  tensor(42.7211)\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity Final: \", torch.mean(torch.tensor(perplexity_final1)))\n",
    "print(\"Perplexity Boh Original Final: \", torch.mean(torch.tensor(perplexity_boh1)))\n",
    "print(\"Perplexity No Sw Original Final: \", torch.mean(torch.tensor(perplexity_sw1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
