{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3870</th>\n",
       "      <th>able play youtube alexa</th>\n",
       "      <th>0.5</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>able recognize indian accent really well drop ...</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>absolute smart device amazon connect external ...</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3204</td>\n",
       "      <td>absolutely amaze new member family control hom...</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1265</td>\n",
       "      <td>absolutely amaze previously sceptical invest m...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>absolutely cheat customer if buy amazon produc...</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   3870                            able play youtube alexa     0.5  positive\n",
       "0    62  able recognize indian accent really well drop ...  0.2794  positive\n",
       "1   487  absolute smart device amazon connect external ...  0.1827  positive\n",
       "2  3204  absolutely amaze new member family control hom...  0.3682  positive\n",
       "3  1265  absolutely amaze previously sceptical invest m...  0.2333  positive\n",
       "4    53  absolutely cheat customer if buy amazon produc...  0.1350  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/csgrad/sunilruf/int_point/code/sentiment-analysis/EcoPreprocessed.csv\")\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "data = df['able play youtube alexa'].to_list()\n",
    "labels = df['0.5']\n",
    "labels = [1 if label> 0 else 0 for label in labels]\n",
    "print(set(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrad/sunilruf/miniconda3/envs/bio3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encode = (tokenizer.encode_plus(data[0], truncation=True, return_tensors=\"pt\", max_length=128, pad_to_max_length=True,  add_special_tokens=True, return_attention_mask=True, return_token_type_ids=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5532, -0.1086,  0.1753,  ..., -0.6397,  0.0961,  0.7571],\n",
       "         [-0.4816,  0.1920,  0.5954,  ..., -0.5952,  0.4091,  0.1240],\n",
       "         [-0.4712,  0.5855,  0.3801,  ..., -0.8300, -0.3521,  0.0086],\n",
       "         ...,\n",
       "         [-0.0133, -0.1829,  0.4134,  ..., -0.3031, -0.2251,  0.2962],\n",
       "         [-0.1936, -0.3222,  0.1449,  ..., -0.2284, -0.0152,  0.1049],\n",
       "         [ 0.0478, -0.2255,  0.3077,  ..., -0.1250,  0.0764,  0.2384]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(encode['input_ids'], encode['attention_mask']).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(encode['input_ids'], encode['attention_mask'])[0][:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(data):\n",
    "    with torch.no_grad():\n",
    "        encodings = tokenizer.encode_plus(data, truncation=True, return_tensors=\"pt\", max_length=128, pad_to_max_length=True, return_attention_mask=True)\n",
    "        input_ids = encodings['input_ids']\n",
    "        attention_mask = encodings['attention_mask']\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   0%|          | 0/4083 [00:00<?, ?it/s]/home/csgrad/sunilruf/miniconda3/envs/bio3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Generating Embeddings: 100%|██████████| 4083/4083 [02:01<00:00, 33.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Generating Embeddings\")\n",
    "df['embeddings'] = df['able play youtube alexa'].progress_apply(lambda x: generate_bert_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3870</th>\n",
       "      <th>able play youtube alexa</th>\n",
       "      <th>0.5</th>\n",
       "      <th>positive</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>able recognize indian accent really well drop ...</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[tensor(-0.5532), tensor(-0.1086), tensor(0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>absolute smart device amazon connect external ...</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[tensor(-0.1641), tensor(0.1520), tensor(0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3204</td>\n",
       "      <td>absolutely amaze new member family control hom...</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[tensor(-0.2341), tensor(-0.1576), tensor(0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1265</td>\n",
       "      <td>absolutely amaze previously sceptical invest m...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[tensor(-0.0489), tensor(0.3692), tensor(-0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>absolutely cheat customer if buy amazon produc...</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[tensor(-0.2314), tensor(-0.1587), tensor(0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>852</td>\n",
       "      <td>yo yo yo love go if want one smart speaker val...</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>positive</td>\n",
       "      <td>[[tensor(-0.3128), tensor(0.1881), tensor(0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>2163</td>\n",
       "      <td>youtube music</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[[tensor(0.2363), tensor(-0.1207), tensor(0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>2488</td>\n",
       "      <td>youtube support nahi kartasong recognise achha...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[[tensor(-0.5111), tensor(0.0448), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>651</td>\n",
       "      <td>yup proscontrols wipro light amazinglysony bra...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[[tensor(-0.3297), tensor(-0.0442), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>868</td>\n",
       "      <td>zero integration capabilities fire tv devices ...</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>negative</td>\n",
       "      <td>[[tensor(-0.1728), tensor(-0.1476), tensor(0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4083 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      3870                            able play youtube alexa     0.5  \\\n",
       "0       62  able recognize indian accent really well drop ...  0.2794   \n",
       "1      487  absolute smart device amazon connect external ...  0.1827   \n",
       "2     3204  absolutely amaze new member family control hom...  0.3682   \n",
       "3     1265  absolutely amaze previously sceptical invest m...  0.2333   \n",
       "4       53  absolutely cheat customer if buy amazon produc...  0.1350   \n",
       "...    ...                                                ...     ...   \n",
       "4078   852  yo yo yo love go if want one smart speaker val...  0.4571   \n",
       "4079  2163                                      youtube music  0.0000   \n",
       "4080  2488  youtube support nahi kartasong recognise achha...  0.0000   \n",
       "4081   651  yup proscontrols wipro light amazinglysony bra...  0.0000   \n",
       "4082   868  zero integration capabilities fire tv devices ... -0.3125   \n",
       "\n",
       "      positive                                         embeddings  \n",
       "0     positive  [[tensor(-0.5532), tensor(-0.1086), tensor(0.1...  \n",
       "1     positive  [[tensor(-0.1641), tensor(0.1520), tensor(0.13...  \n",
       "2     positive  [[tensor(-0.2341), tensor(-0.1576), tensor(0.1...  \n",
       "3     positive  [[tensor(-0.0489), tensor(0.3692), tensor(-0.2...  \n",
       "4     positive  [[tensor(-0.2314), tensor(-0.1587), tensor(0.1...  \n",
       "...        ...                                                ...  \n",
       "4078  positive  [[tensor(-0.3128), tensor(0.1881), tensor(0.05...  \n",
       "4079   neutral  [[tensor(0.2363), tensor(-0.1207), tensor(0.04...  \n",
       "4080   neutral  [[tensor(-0.5111), tensor(0.0448), tensor(-0.0...  \n",
       "4081   neutral  [[tensor(-0.3297), tensor(-0.0442), tensor(-0....  \n",
       "4082  negative  [[tensor(-0.1728), tensor(-0.1476), tensor(0.0...  \n",
       "\n",
       "[4083 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = df['embeddings'].to_list()\n",
    "print(encodings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = torch.stack(encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4083, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "print((tensors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (fc1): Linear(in_features=768, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "classifier = BertClassifier(768, 100, 2)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tensors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = TensorDataset(X_train, torch.tensor(y_train))\n",
    "test_data = TensorDataset(X_test, torch.tensor(y_test))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for i in range(10):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X = X.view(X.size(0), -1)\n",
    "            pred = model(X)\n",
    "            print(pred.shape, y.shape)\n",
    "            y = y.float()\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrad/sunilruf/miniconda3/envs/bio3/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[136], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/bio3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/bio3/lib/python3.11/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bio3/lib/python3.11/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/envs/bio3/lib/python3.11/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, classifier, loss_fn, optimizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, loss_fn, optimizer):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for X, y in dataloader:\n",
    "        print(X.shape)\n",
    "        X = X.view(X.size(0), -1)\n",
    "        #print(X.shape)\n",
    "        pred = model(X)\n",
    "        #print(pred)\n",
    "        pred = (torch.argmax(pred,1))\n",
    "        print(len(y))\n",
    "        accuracy = (pred == y).sum().item()\n",
    "        print((accuracy/len(y))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "81.25\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "87.5\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "90.625\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "87.5\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "90.625\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "87.5\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "93.75\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "93.75\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "90.625\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "87.5\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "75.0\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "81.25\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "90.625\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "93.75\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "87.5\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "87.5\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "84.375\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "90.625\n",
      "torch.Size([32, 1, 768])\n",
      "32\n",
      "90.625\n",
      "torch.Size([17, 1, 768])\n",
      "17\n",
      "94.11764705882352\n"
     ]
    }
   ],
   "source": [
    "test(classifier, test_dataloader, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
