{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8722539ff7d74c3387adad5800bc0f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/csgrad/sunilruf/'\n",
    "path = \"/home/csgrad/sunilruf/emotion_chatbot/master/sunils_code/mistra/rank_64/rank_64_2/checkpoint-50\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForCausalLM.from_pretrained(path, load_in_4bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 910\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 195\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 195\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"thu-coai/esconv\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(dataset['test'][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lot of people lose the job in this corona time'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dialog'][6]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "import evaluate\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference:  ok tell me\n",
      "Candidate:   Hello Tom, I'm here to help. What's been going on?\n",
      "Individual 1-gram: 0.117647\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.2919])\n",
      "Recall: tensor([0.4304])\n",
      "F1 Score: tensor([0.3479])\n",
      "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "Reference:  ok, don't worry friend,\n",
      "Candidate:   I can imagine how difficult and stressful it must be for you to be facing the possibility of losing your job during these uncertain times. It's completely understandable that you're feeling overwhelmed and worried about the future.\n",
      "Individual 1-gram: 0.051724\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.2510])\n",
      "Recall: tensor([0.4093])\n",
      "F1 Score: tensor([0.3111])\n",
      "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "Reference:  lot of people lose the job in this corona time\n",
      "Candidate:   While I can't guarantee a specific outcome, I can suggest some steps you can take to communicate your concerns to your boss. Firstly, express your concerns and explain how losing your job would impact your family and personal life. Be honest and open about your situation. Additionally, you could propose alternative solutions such as reducing work hours or implementing cost-saving measures.\n",
      "Individual 1-gram: 0.043257\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.3079])\n",
      "Recall: tensor([0.4342])\n",
      "F1 Score: tensor([0.3603])\n",
      "{'rouge1': 0.0273972602739726, 'rouge2': 0.0, 'rougeL': 0.0273972602739726, 'rougeLsum': 0.0273972602739726}\n",
      "Reference:  Incase i lose the job, are there ways that can help me stay out of stress of losing the job?\n",
      "Candidate:   Absolutely, I understand. It can be challenging to convey our emotions and concerns, especially when we're facing difficult situations. Remember, it's important to express yourself with sincerity and empathy. Be clear about your feelings and explain how the potential job loss would impact your family and personal life. Your boss may be more understanding and open to dialogue once they understand the gravity of your situation.\n",
      "Individual 1-gram: 0.053488\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.3888])\n",
      "Recall: tensor([0.4673])\n",
      "F1 Score: tensor([0.4245])\n",
      "{'rouge1': 0.13636363636363635, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "Reference:  definitely, you have to try to get the other work\n",
      "Candidate:   I can understand why you're feeling worried and uncertain about your financial situation. Losing a job can indeed bring about a lot of financial stress. It's important to start exploring alternative options. You could consider looking for other job opportunities, or even starting a side business. It may take time and effort, but it's worth exploring. Additionally, you may want to reach out to your network or seek professional advice from a career counselor.\n",
      "Individual 1-gram: 0.041126\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.3685])\n",
      "Recall: tensor([0.5139])\n",
      "F1 Score: tensor([0.4292])\n",
      "{'rouge1': 0.09195402298850576, 'rouge2': 0.0, 'rougeL': 0.0689655172413793, 'rougeLsum': 0.0689655172413793}\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "for i in range(1, len(data), 2):\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\":  data['dialog'][i]['text']})\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "    )\n",
    "    candidate = (tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].split(\"[/INST]\")[-1])\n",
    "    reference = data['dialog'][i+1]['text']\n",
    "    candidates = candidate.split(\" \")\n",
    "    references = reference.split(\" \")\n",
    "    print(\"Reference: \", reference)\n",
    "    print(\"Candidate: \", candidate)\n",
    "    print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
    "    print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
    "    print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
    "    print('Individual 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 0, 1)))\n",
    "    print('Cumulative 1-gram: %f' % sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "    P, R, F1 = score([candidate], [reference], lang='en', model_type='bert-base-uncased')\n",
    "\n",
    "# Print the BERTScore\n",
    "    print('Precision:', P)\n",
    "    print('Recall:', R)\n",
    "    print('F1 Score:', F1)\n",
    "    results = rouge.compute(predictions=[candidate], references=[reference])\n",
    "    print(results)\n",
    "    messages.append({\"role\": \"assistant\", \"content\": candidate})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = '../../ExTES.json'  # Change 'output.json' to your desired file name\n",
    "\n",
    "# Write the list to the JSON file\n",
    "with open(json_file_path, 'rb') as json_file:\n",
    "    extes_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extes_data[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey, are you free? I need someone to talk to.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['User']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from bert_score import score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference:  Of course! I'm here to listen. What's been going on?\n",
      "Candidate:   Of course! I'm here to listen. What's been going on?\n",
      "Individual 1-gram: 0.000000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([1.])\n",
      "Recall: tensor([1.])\n",
      "F1 Score: tensor([1.])\n",
      "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "Reference:  That sounds really tough. It's completely normal to feel confused and insecure when a situation like this arises. Have you had any discussions about needing space in the past?\n",
      "Candidate:  I can understand how challenging and painful that must be for you. It sounds like you're feeling confused and hurt.\n",
      "Individual 1-gram: 0.050000\n",
      "Individual 2-gram: 0.015767\n",
      "Individual 3-gram: 0.008321\n",
      "Individual 4-gram: 0.004405\n",
      "Cumulative 1-gram: 0.013039\n",
      "Precision: tensor([0.5615])\n",
      "Recall: tensor([0.4799])\n",
      "F1 Score: tensor([0.5175])\n",
      "{'rouge1': 0.27450980392156865, 'rouge2': 0.04081632653061224, 'rougeL': 0.1568627450980392, 'rougeLsum': 0.1568627450980392}\n",
      "Reference:  I can understand why you would feel that way. It's natural to jump to conclusions and worry about the state of your relationship. Remember, it's crucial not to blame yourself. Relationships go through ups and downs, and communication is key.\n",
      "Candidate:  It's understandable to worry and fear the worst. However, it's important to remember that communication is key in any relationship. Have you tried having an open and honest conversation about your concerns and feelings?\n",
      "Individual 1-gram: 0.000000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.6349])\n",
      "Recall: tensor([0.6075])\n",
      "F1 Score: tensor([0.6209])\n",
      "{'rouge1': 0.5128205128205129, 'rouge2': 0.10526315789473684, 'rougeL': 0.2820512820512821, 'rougeLsum': 0.2820512820512821}\n",
      "Reference:  You could consider expressing your feelings to your significant other calmly and honestly. Let them know you're there to listen and that you want to understand their needs and concerns. It's also essential to give them the space they asked for, even if it's difficult for you.\n",
      "Candidate:  It can be challenging to approach such a sensitive conversation. Maybe you could start by expressing your concerns and asking for their perspective? It shows that you care and want to understand what's going on.\n",
      "Individual 1-gram: 0.028571\n",
      "Individual 2-gram: 0.010457\n",
      "Individual 3-gram: 0.005387\n",
      "Individual 4-gram: 0.002778\n",
      "Cumulative 1-gram: 0.008177\n",
      "Precision: tensor([0.6159])\n",
      "Recall: tensor([0.6006])\n",
      "F1 Score: tensor([0.6081])\n",
      "{'rouge1': 0.41860465116279066, 'rouge2': 0.11904761904761904, 'rougeL': 0.2558139534883721, 'rougeLsum': 0.2558139534883721}\n",
      "Reference:  I understand how challenging it can be to wait and give someone space when you're feeling unsure. Maybe you can focus on self-care during this time to help you manage your emotions. Doing things you enjoy and spending time with friends and family can provide support.\n",
      "Candidate:  I completely understand. It's challenging to wait and be patient during uncertain times. Remember, giving them space doesn't mean you have to abandon your own needs. It's important to take care of yourself as well.\n",
      "Individual 1-gram: 0.028571\n",
      "Individual 2-gram: 0.010457\n",
      "Individual 3-gram: 0.005387\n",
      "Individual 4-gram: 0.002778\n",
      "Cumulative 1-gram: 0.008177\n",
      "Precision: tensor([0.6191])\n",
      "Recall: tensor([0.5959])\n",
      "F1 Score: tensor([0.6073])\n",
      "{'rouge1': 0.32558139534883723, 'rouge2': 0.047619047619047616, 'rougeL': 0.23255813953488372, 'rougeLsum': 0.23255813953488372}\n",
      "Reference:  You're welcome! Remember, you're not alone in this. If you ever need to talk or confront any concerns, feel free to reach out. Your feelings and needs are valid. Take care of yourself during this challenging time.\n",
      "Candidate:  You're welcome! Remember, you're not alone in this. It's great that you have someone to talk to and seek support. Take care of yourself and try to find some positivity in this situation. It's only temporary, and better days will come.\n",
      "Individual 1-gram: 0.000000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([0.6574])\n",
      "Recall: tensor([0.7101])\n",
      "F1 Score: tensor([0.6828])\n",
      "{'rouge1': 0.47619047619047616, 'rouge2': 0.3170731707317074, 'rougeL': 0.47619047619047616, 'rougeLsum': 0.47619047619047616}\n",
      "Reference:  You're welcome! I'm here for you. Take care and have a great day too!\n",
      "Candidate:  You're welcome! Take care, and have a wonderful day too. Goodbye!\n",
      "Individual 1-gram: 0.090909\n",
      "Individual 2-gram: 0.023979\n",
      "Individual 3-gram: 0.013322\n",
      "Individual 4-gram: 0.007493\n",
      "Cumulative 1-gram: 0.021598\n",
      "Precision: tensor([0.8725])\n",
      "Recall: tensor([0.8264])\n",
      "F1 Score: tensor([0.8488])\n",
      "{'rouge1': 0.7142857142857143, 'rouge2': 0.5384615384615385, 'rougeL': 0.7142857142857143, 'rougeLsum': 0.7142857142857143}\n",
      "Reference:  Goodbye!\n",
      "Candidate:  Goodbye!\n",
      "Individual 1-gram: 0.000000\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n",
      "Cumulative 1-gram: 0.000000\n",
      "Precision: tensor([1.])\n",
      "Recall: tensor([1.])\n",
      "F1 Score: tensor([1.])\n",
      "{'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "for i in range(0, len(data), 2):\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\":  data[i]['User']})\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "    )\n",
    "    candidate = (tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].split(\"[/INST]\")[-1])\n",
    "    reference = data[i+1]['AI']\n",
    "    \n",
    "    references = reference.split(\" \")\n",
    "    candidates = candidate.split(\" \")\n",
    "    print(\"Reference: \", reference)\n",
    "    print(\"Candidate: \", candidate)\n",
    "    smoothie = SmoothingFunction().method4\n",
    "\n",
    "# Calculate BLEU scores with smoothing\n",
    "    print('Individual 1-gram: %f' % sentence_bleu(references, candidates, weights=(1, 0, 0, 0), smoothing_function=smoothie))\n",
    "    print('Individual 2-gram: %f' % sentence_bleu(references, candidates, weights=(0, 1, 0, 0), smoothing_function=smoothie))\n",
    "    print('Individual 3-gram: %f' % sentence_bleu(references, candidates, weights=(0, 0, 1, 0), smoothing_function=smoothie))\n",
    "    print('Individual 4-gram: %f' % sentence_bleu(references, candidates, weights=(0, 0, 0, 1), smoothing_function=smoothie))\n",
    "    print('Cumulative 1-gram: %f' % sentence_bleu(references, candidates, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie))\n",
    "    P, R, F1 = score([candidate], [reference], lang='en', model_type='bert-base-uncased')\n",
    "\n",
    "# Print the BERTScore\n",
    "    print('Precision:', P)\n",
    "    print('Recall:', R)\n",
    "    print('F1 Score:', F1)\n",
    "    results = rouge.compute(predictions=[candidate], references=[reference])\n",
    "    print(results)\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reference})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
